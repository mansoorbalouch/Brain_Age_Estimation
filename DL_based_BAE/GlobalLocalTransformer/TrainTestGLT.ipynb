{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GlobalLocalTransformer import *\n",
    "import torch as nn\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.ndimage as nd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score,mean_absolute_error\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "number is: 10\n"
     ]
    }
   ],
   "source": [
    "# create input embeddings 'zlist'\n",
    "\n",
    "# 5 represents the number of channels or the depth of the 2D slices\n",
    "# 130 * 170 represent the height and width of a 2D slice\n",
    "# torch.rand()\n",
    "\n",
    "x1 = torch.rand(10,5,128,128)\n",
    "    \n",
    "mod = GlobalLocalBrainAge(5,\n",
    "                    patch_size=32,\n",
    "                    step=32,\n",
    "                    nblock=6,\n",
    "                    backbone='vgg8')\n",
    "zlist = mod(x1)\n",
    "for z in zlist:\n",
    "    print(z.shape)\n",
    "print('number is:',len(zlist))\n",
    "# print(zlist)\n",
    "# print(x1[:,:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data matrix loaded... shape:  (20, 121, 145, 121, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "src = \"/media/dataanalyticlab/Drive2/MANSOOR/Dataset/Test/\"\n",
    "X = np.load(src + \"VBM_OpenBHB.npy\")\n",
    "Y = pd.read_csv(src + \"SubInfoOpenBHB.csv\")\n",
    "print(\"Data matrix loaded... shape: \", X.shape )\n",
    "labels = Y.loc[:,\"age\"]\n",
    "x = X[:,:,:,60:65,0]\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 5, 121, 145])\n",
      "torch.Size([4, 5, 121, 145])\n",
      "torch.Size([16]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x,labels, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_train = X_train.permute(0,3,1,2)\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "X_test = torch.from_numpy(X_test)\n",
    "X_test = X_test.permute(0,3,1,2)\n",
    "print(X_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "Y_train = torch.from_numpy(np.array(Y_train))\n",
    "Y_test = torch.from_numpy(np.array(Y_test))\n",
    "\n",
    "print(Y_train.shape, Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train(model, X, labels, batch_size=64, num_epochs=5):\n",
    "    # set MAE as the loss function for brain age predciction \n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    # training\n",
    "    n = 0 # the number of iterations\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(len(X)):\n",
    "            zlist = model(X)             # forward pass\n",
    "            prob = F.softmax(zlist[0][i], dim=0) \n",
    "            loss = criterion(prob, labels) # compute the total loss\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "            optimizer.step()              # make the updates for each parameter\n",
    "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
    "\n",
    "            # save the current training information\n",
    "            iters.append(n)\n",
    "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
    "            train_acc.append(get_accuracy(model, X,labels)) # compute training accuracy \n",
    "            print(train_acc)\n",
    "            # val_acc.append(get_accuracy(model, X_test))  # compute validation accuracy\n",
    "            n += 1\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, X_set, Y_set):\n",
    "   \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(X_set)):\n",
    "        output = model(X_set) # We don't need to run F.softmax\n",
    "        pred = output[0].max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(Y_set.view_as(pred)).sum().item()\n",
    "        total += X_set[i].shape[0]\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dataanalyticlab/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "model = GlobalLocalBrainAge(5,\n",
    "                        patch_size=128,\n",
    "                        step=32,\n",
    "                        nblock=6,\n",
    "                        backbone='vgg8')\n",
    "# \n",
    "model = model.double()\n",
    "acc = train(model, X_train, Y_train)\n",
    "# zlist = model(x)\n",
    "# for z in zlist:\n",
    "    # print(z.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2627], dtype=torch.float64, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# prob = F.softmax(zlist[0], dim=0)\n",
    "print(zlist[0][5])\n",
    "# print(sum(prob[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4166],\n",
       "        [-0.3347],\n",
       "        [-0.4152],\n",
       "        [-0.2939],\n",
       "        [-0.2174],\n",
       "        [-0.2627],\n",
       "        [-0.4650],\n",
       "        [-0.2199],\n",
       "        [-0.3386],\n",
       "        [-0.0836],\n",
       "        [-0.3961],\n",
       "        [-0.3762],\n",
       "        [-0.2319],\n",
       "        [-0.3487],\n",
       "        [-0.2062]], dtype=torch.float64, grad_fn=<AliasBackward0>)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.Tensor(zlist[0])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = ViTForClassfication( 7, 1)\n",
    "a = mod(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTForClassfication(nn.Module):\n",
    "    \"\"\"\n",
    "    The ViT model for classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        # self.config = config\n",
    "        # self.image_size = config[\"image_size\"]\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.zlist = zlist\n",
    "        # Create the embedding module\n",
    "        # self.embedding = Embeddings(config)\n",
    "        # Create the transformer encoder module\n",
    "        # self.encoder = Encoder(config)\n",
    "        # Create a linear layer to project the encoder's output to the number of classes\n",
    "        self.classifier = nn.Linear(self.hidden_size, 1)\n",
    "        # Initialize the weights\n",
    "        # self.apply(self._init_weights)\n",
    "\n",
    "    def forward(self, zlist, output_attentions=False):\n",
    "        # Calculate the embedding output\n",
    "        # embedding_output = self.embedding(x)\n",
    "        encoder_output = self.zlist\n",
    "        # Calculate the encoder's output\n",
    "        # encoder_output, all_attentions = self.encoder(embedding_output, output_attentions=output_attentions)\n",
    "        # Calculate the logits, take the [CLS] token's output as features for classification\n",
    "        logits = self.classifier(encoder_output)\n",
    "        # Return the logits and the attention probabilities (optional)\n",
    "        if not output_attentions:\n",
    "            return (logits, None)\n",
    "        else:\n",
    "            return (logits, all_attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/media/dataanalyticlab/Drive2/MANSOOR/Neuroimaging_Project/Code/Brain_Age_Estimation/DL_based_BAE/GlobalLocalTransformer/TrainTestGLT.ipynb Cell 11\u001b[0m in \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/dataanalyticlab/Drive2/MANSOOR/Neuroimaging_Project/Code/Brain_Age_Estimation/DL_based_BAE/GlobalLocalTransformer/TrainTestGLT.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/dataanalyticlab/Drive2/MANSOOR/Neuroimaging_Project/Code/Brain_Age_Estimation/DL_based_BAE/GlobalLocalTransformer/TrainTestGLT.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Define the optimizer\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/dataanalyticlab/Drive2/MANSOOR/Neuroimaging_Project/Code/Brain_Age_Estimation/DL_based_BAE/GlobalLocalTransformer/TrainTestGLT.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#optimizer = torch.optim.Adam(model.parameters(), lr=lr)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/dataanalyticlab/Drive2/MANSOOR/Neuroimaging_Project/Code/Brain_Age_Estimation/DL_based_BAE/GlobalLocalTransformer/TrainTestGLT.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr)\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/dataanalyticlab/Drive2/MANSOOR/Neuroimaging_Project/Code/Brain_Age_Estimation/DL_based_BAE/GlobalLocalTransformer/TrainTestGLT.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# initialize SaveBestModel class\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/dataanalyticlab/Drive2/MANSOOR/Neuroimaging_Project/Code/Brain_Age_Estimation/DL_based_BAE/GlobalLocalTransformer/TrainTestGLT.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m save_best_model \u001b[39m=\u001b[39m SaveBestModel(save_dir\u001b[39m=\u001b[39msave_checkpoint)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lr' is not defined"
     ]
    }
   ],
   "source": [
    "# define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "# Define the optimizer\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# initialize SaveBestModel class\n",
    "save_best_model = SaveBestModel(save_dir=save_checkpoint)\n",
    "\n",
    "# training\n",
    "def train(model, trainloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    print('Training')\n",
    "    train_running_loss = 0.0\n",
    "    counter = 0\n",
    "    for i, data in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
    "        counter += 1\n",
    "        inputs, targets = data\n",
    "        image = inputs.to(device)\n",
    "        labels = targets.to(device)\n",
    "        labels = labels.reshape((labels.shape[0], 1))\n",
    "        labels = labels.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        outputs = model(image)\n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_running_loss += loss.item()\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        # update the optimizer parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    # loss for the complete epoch\n",
    "    epoch_loss = train_running_loss / counter\n",
    "\n",
    "    return epoch_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
